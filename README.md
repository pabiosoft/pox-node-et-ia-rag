#  RAG Chat Bot

Un chatbot simple qui rÃ©pond Ã  vos questions en cherchant dans vos documents.

![RAG Chat Bot Demo](./backend/public/images/demo-screenshot.jpeg)

Features :
- [] Chatbot avec historique
- [x] Indexation de documents `.json` et `.xlsx`
- [x] Recherche vectorielle avec seuil adaptatif
- [x] GÃ©nÃ©ration de rÃ©ponse avec GPT
- [x] Affichage des sources
- [x] Gestion des salutations
- [ ] Tests unitaires
- [ ] Documentation
- [ ] DÃ©ploiement

##  DÃ©marrage rapide

### 1. Cloner le projet
```bash
git clone hhttps://github.com/pabiosoft/pox-node-et-ia-rag.git
cd pox-node-et-ia-rag
```

### 2. Configuration
```bash
cd backend
cp .env.example .env
# Ã‰diter .env et ajouter vos clÃ©s API
```

### 3. Lancer l'application
```bash
docker compose up --build
```

### 4. Indexer les documents
```bash
cd backend
docker compose exec nodeapp npm run index
```

### 5. Utiliser l'application
- **Chat** : http://localhost:8000
- **Qdrant Dashboard** : http://localhost:6333/dashboard

##  Recherche Web Automatique (Nouveau)

Le systÃ¨me peut maintenant rechercher automatiquement sur Internet lorsque aucune rÃ©ponse n'est trouvÃ©e dans le corpus local et gÃ©nÃ©rer de nouveaux documents.

### Configuration requise

Ajoutez votre clÃ© Serper dans `.env` :
```env
SERPER_KEY=votre_cle_serper_ici
```

> ğŸ’¡ Obtenez une clÃ© gratuite sur [https://serper.dev/](https://serper.dev/)

### Fonctionnement

1. **DÃ©tection automatique** : Lorsque l'IA ne trouve pas de rÃ©ponse dans le corpus
2. **Recherche web** : Utilisation de Serper pour trouver des sources pertinentes
3. **Extraction de contenu** : RÃ©cupÃ©ration du contenu des pages web
4. **GÃ©nÃ©ration de document** : CrÃ©ation d'un document structurÃ© avec GPT
5. **Sauvegarde automatique** : Le document est enregistrÃ© dans `backend/corpus/auto-generated/`
6. **Indexation automatique** : Le document est ajoutÃ© Ã  la base vectorielle
7. **RÃ©ponse Ã  l'utilisateur** : L'IA rÃ©pond avec les informations trouvÃ©es

### Exemple de workflow

```
Utilisateur: "Quelles sont les derniÃ¨res avancÃ©es en intelligence artificielle en 2024 ?"
    â†“
IA: "Je n'ai pas d'informations dans ma base..."
    â†“
ğŸ” Recherche web automatique...
    â†“
âœ… Document gÃ©nÃ©rÃ©: "Recherche: derniÃ¨res avancÃ©es IA 2024..."
    â†“
ğŸ”„ Document indexÃ© dans Qdrant
    â†“
IA: "J'ai trouvÃ© des informations pertinentes sur le web et je les ai ajoutÃ©es Ã  ma base...
     [RÃ©ponse dÃ©taillÃ©e avec les informations trouvÃ©es]"
```

### Structure des documents (format obligatoire)

**Tous les documents** (manuels et auto-gÃ©nÃ©rÃ©s) doivent suivre ce format strict pour Ãªtre indexÃ©s :

```json
{
  "title": "Titre du document",
  "author": "Auteur",
  "date": "YYYY-MM-DD",
  "category": "CatÃ©gorie",
  "text": "Contenu textuel complet"
}
```

**Exemple de document auto-gÃ©nÃ©rÃ©** :
```json
{
  "title": "Recherche: Quelles sont les derniÃ¨res avancÃ©es en IA en 2024",
  "author": "IA Research Assistant",
  "date": "2024-12-26",
  "category": "IA",
  "text": "En 2024, les avancÃ©es en intelligence artificielle ont Ã©tÃ© marquÃ©es par..."
}
```

> âš ï¸ **Important** : Tout document ne respectant pas ce format ne sera pas indexÃ© par le systÃ¨me.

### Gestion des documents auto-gÃ©nÃ©rÃ©s

- **Dossier** : `backend/corpus/auto-generated/`
- **Format** : Fichiers JSON au format obligatoire
- **RÃ©indexation** : Automatique via la file d'attente
- **DÃ©duplication** : VÃ©rification automatique des questions dÃ©jÃ  recherchÃ©es

### Validation des documents

Un script de validation est disponible pour vÃ©rifier que tous les documents respectent le format obligatoire :

```bash
# ExÃ©cuter la validation
npm run validate
```

Ce script vÃ©rifie :
- Tous les champs obligatoires sont prÃ©sents
- Les types de donnÃ©es sont corrects
- Le format de la date est valide (YYYY-MM-DD)
- Aucun champ supplÃ©mentaire n'est prÃ©sent

Le script retourne un code d'erreur (1) si des documents sont invalides, ce qui permet de l'intÃ©grer dans des pipelines CI/CD.

### Test de l'intÃ©gration Serper

Un script de test est disponible pour vÃ©rifier que l'intÃ©gration Serper fonctionne correctement :

```bash
# Tester la connexion Serper
npm run test-serper
```

Ce script :
- VÃ©rifie la configuration de SERPER_KEY
- Effectue une recherche test
- Affiche les rÃ©sultats
- Valide que l'API rÃ©pond correctement

IdÃ©al pour vÃ©rifier que votre clÃ© Serper est valide et que l'intÃ©gration fonctionne avant de lancer l'application.

### DÃ©sactivation

Pour dÃ©sactiver la recherche web, supprimez simplement la clÃ© `SERPAPI_KEY` du fichier `.env`.

##  Ajouter des documents au corpus

1. Ajoutez vos fichiers `.json` dans `backend/corpus/`
2. Relancez l'indexer :
```bash
docker compose exec nodeapp npm run index
```

##  Stack technique

- Node.js + Express
- OpenAI API (GPT + Embeddings)
- Qdrant (base vectorielle)
- Docker
- Serper (recherche web)
- Cheerio (extraction de contenu)
- Axios (requÃªtes HTTP)

##  Licence

MIT - Voir [LICENSE](LICENSE)

##  Architecture Technique

### Nouveaux Services AjoutÃ©s

#### 1. `webSearchService.js`
- **ResponsabilitÃ©** : Recherche web et gÃ©nÃ©ration de documents
- **FonctionnalitÃ©s** :
  - Recherche avec Serper (API REST)
  - Extraction de contenu avec Cheerio
  - GÃ©nÃ©ration de documents structurÃ©s avec GPT
  - Sauvegarde dans le systÃ¨me de fichiers
  - DÃ©tection de doublons

#### 2. `indexationQueue.js`
- **ResponsabilitÃ©** : Gestion de l'indexation par lots
- **FonctionnalitÃ©s** :
  - File d'attente pour les documents Ã  indexer
  - Traitement par lots (batch processing)
  - Gestion des erreurs et retries
  - Optimisation des performances

#### 3. Modifications dans `ragService.js`
- **Nouvelle mÃ©thode** : `handleWebSearchFallback()`
- **IntÃ©gration** : DÃ©tection des Ã©checs et appel automatique Ã  la recherche web
- **Workflow** : Gestion complÃ¨te du processus de recherche et d'indexation

### Diagramme de Flux

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Utilisateur Pose Question              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   RAGService.processQuestion()          â”‚
â”‚                   1. VÃ©rification salutations           â”‚
â”‚                   2. Recherche vectorielle             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   RÃ©sultats trouvÃ©s ?                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Oui â†’ Retourne rÃ©ponse avec sources                   â”‚
â”‚ Non â†’ Appelle handleWebSearchFallback()               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               WebSearchService.searchAndGenerate()     â”‚
â”‚               1. Recherche SerpAPI                     â”‚
â”‚               2. Extraction contenu pages              â”‚
â”‚               3. GÃ©nÃ©ration document GPT               â”‚
â”‚               4. Sauvegarde fichier JSON               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               IndexationQueue.add()                    â”‚
â”‚               - Ajout Ã  la file d'attente               â”‚
â”‚               - Traitement par lots                    â”‚
â”‚               - Indexation dans Qdrant                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               RÃ©ponse Ã  l'utilisateur                  â”‚
â”‚               - Confirmation de recherche              â”‚
â”‚               - Informations trouvÃ©es                  â”‚
â”‚               - Sources et mÃ©tadonnÃ©es                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration et Variables d'Environnement

**Nouveaux paramÃ¨tres dans `.env`** :
```env
# Recherche web
SERPER_KEY=votre_cle_serper
WEB_SEARCH_ENABLED=true
WEB_SEARCH_MAX_RESULTS=5
WEB_SEARCH_TIMEOUT=10000
```

### Bonnes Pratiques ImplÃ©mentÃ©es

1. **Gestion des erreurs** : Try/catch Ã  tous les niveaux avec fallbacks
2. **Optimisation** : Batch processing pour les indexations
3. **SÃ©curitÃ©** : Limitation des requÃªtes et timeouts
4. **MaintenabilitÃ©** : Code modulaire et bien documentÃ©
5. **CompatibilitÃ©** : IntÃ©gration transparente avec le systÃ¨me existant

### Performances

- **Batch size** : 5 documents par lot (optimal pour OpenAI)
- **Concurrency** : 1 batch Ã  la fois pour Ã©viter la surcharge
- **Retry logic** : 3 tentatives avec backoff exponentiel
- **Timeouts** : 10 secondes par requÃªte web

### Limites et AmÃ©liorations Futures

**Limites actuelles** :
- DÃ©pendance Ã  Serper (nÃ©cessite une clÃ© API)
- Limite de 3 URLs scrapÃ©es par recherche
- Pas de systÃ¨me de cache pour les recherches web

**AmÃ©liorations possibles** :
- Ajouter un cache Redis pour les recherches web
- ImplÃ©menter un systÃ¨me de notation des sources
- Ajouter des tests unitaires complets
- Optimiser la dÃ©duplication avec des embeddings
- Ajouter un systÃ¨me de feedback utilisateur

